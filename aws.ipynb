{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7e8d6-1411-4158-bf08-ce271c532ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS production is integrated with Splunk ES using Splunk Add-on for AWS.\n",
    "Logs are stored in aws_security index and collected using two best-practice methods:\n",
    "\n",
    "Pull-based Modular Inputs + Push-based HEC inputs.\n",
    "\n",
    "Pull-based: Splunk goes to the source and collects logs (Splunk initiates the connection)\n",
    "\n",
    "Push-based: Source sends logs to Splunk (Source initiates the connection)\n",
    "\n",
    "| Application/Device name | Source Types               | Data Collection Method | Data Collection Frequency | Index Name   | Platform | Syslog Servers              |\n",
    "| ----------------------- | -------------------------- | ---------------------- | ------------------------- | ------------ | -------- | --------------------------- |\n",
    "| AWS                     | aws:cloudtrail             | Modular Input          | Every 5 minutes           | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:cloudwatch             | Modular Input          | Every 5 minutes           | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:config                 | Modular Input          | Every 3 minutes           | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:s3:accesslogs          | Modular Input          | Every 5 minutes           | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:cloudwatch:guardduty   | Modular Input          | Every 30 seconds          | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:config:rule            | Modular Input          | Every 5 minutes           | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:metadata               | Modular Input          | Every 10 minutes          | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:securityhub:finding    | HEC Input              | Real Time                 | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:cloudwatchlogs:vpcflow | HEC Input              | Real Time                 | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "| AWS                     | aws:accessanalyzer:finding | HEC Input              | Real Time                 | aws_security | AWS Prod | SPLUNK-HFSYS02 / 10.2.8.142 |\n",
    "\n",
    "\n",
    "Configuration On Deployment Server: \n",
    "A Serverclass afrex_all_aws_addon is created on the Deployment server for deploying the below add-on \n",
    "on the AWS Syslog/HF02 server to collect various AWS log sources.\n",
    "\n",
    "Update serverclass.conf: \n",
    "To avoid overwriting/deleting inputs during add-on upgrades, edit the serverclass.conf file on Deployment \n",
    "server and add the below parameter under the Salesforce serverclass as shown below \n",
    "excludeFromUpdate = $app_root$/local \n",
    "/opt/splunk/etc/system/local/serverclass.conf \n",
    "[serverClass:afrexim_all_aws_addon:app:Splunk_TA_aws] \n",
    "restartSplunkWeb = 0 \n",
    "restartSplunkd = 1 \n",
    "stateOnClient = enabled \n",
    "excludeFromUpdate = $app_root$/local\n",
    "\n",
    "Configure AWS API Account on Splunk \n",
    "Collect Key ID, Secret Key of an AWS API account to integrate splunk with AWS cloud and add the account \n",
    "details on AWS Syslog/HF02 server as shown below.\n",
    "\n",
    "More Info: \n",
    "https://www.cloud.northwestern.edu/resources/howtos/sending-aws-logs-to-splunk/ \n",
    "https://docs.splunk.com/Documentation/AddOns/released/AWS/Setuptheadd-on \n",
    "\n",
    "\n",
    "Short & simple:\n",
    "\n",
    "CloudTrail → tracks who did what in AWS (API activity/audit)\n",
    "\n",
    "CloudWatch → collects AWS service/system logs & metrics\n",
    "\n",
    "Config / Config Rules → tracks resource changes & compliance\n",
    "\n",
    "GuardDuty → collects threat detections\n",
    "\n",
    "S3 Access Logs → tracks who accessed S3 buckets/objects\n",
    "\n",
    "Metadata → collects AWS account/resource inventory details\n",
    "\n",
    "\n",
    "CloudWatch Log Group generates logs from AWS services/applications.\n",
    "\n",
    "We attach a Subscription Filter to that log group, which forwards every new log event in real time to Lambda.\n",
    "\n",
    "Lambda receives the CloudWatch log batch (awslogs.data), decodes/decompresses it, and stores the processed logs as .json.gz files in S3.\n",
    "\n",
    "On every new file creation, S3 Event Notification triggers SNS to publish a message.\n",
    "\n",
    "SNS forwards that message to SQS, so messages are buffered safely.\n",
    "\n",
    "Splunk TA-AWS pulls SQS continuously, reads the message, and gets the S3 object path.\n",
    "\n",
    "Splunk then downloads the file from S3 and indexes the events into the aws_security index.\n",
    "\n",
    "AWS Admin tasks\n",
    "\n",
    "Create S3 bucket + prefix\n",
    "\n",
    "Create IAM policy + IAM role for Lambda\n",
    "\n",
    "Create Lambda function (CloudWatch logs → write to S3)\n",
    "\n",
    "Create/identify CloudWatch Log Group\n",
    "\n",
    "Create Subscription Filter (Log Group → Lambda)\n",
    "\n",
    "Create SNS topic\n",
    "\n",
    "Create SQS queue\n",
    "\n",
    "Subscribe SQS to SNS\n",
    "\n",
    "Configure SNS policy (allow S3 to publish)\n",
    "\n",
    "Configure S3 Event Notification (S3 → SNS)\n",
    "\n",
    "Create IAM user/role for Splunk + provide Access/Secret keys + Queue URL\n",
    "\n",
    "✅ Splunk Admin tasks\n",
    "\n",
    "Install/configure Splunk Add-on for AWS (TA-AWS)\n",
    "\n",
    "Add AWS Account in TA-AWS (Access Key + Secret + Region)\n",
    "\n",
    "Create SQS-Based S3 input\n",
    "\n",
    "Queue URL\n",
    "\n",
    "S3 bucket/prefix/suffix\n",
    "\n",
    "Index = aws_security\n",
    "\n",
    "Sourcetype\n",
    "\n",
    "Validate ingestion in Splunk using search and monitoring logs\n",
    "\n",
    "Queue URL ?\n",
    "✅ What is Queue URL?\n",
    "\n",
    "Queue URL = the unique web address of the SQS queue that Splunk uses to read messages.\n",
    "\n",
    "It looks like this:\n",
    "https://sqs.<region>.amazonaws.com/<account-id>/<queue-name>\n",
    "\n",
    "Example:\n",
    "https://sqs.ap-south-1.amazonaws.com/123456789012/cloudwatch-splunk-queue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SQS Queue URL (must, not ARN)\n",
    "\n",
    "S3 Bucket name\n",
    "\n",
    "S3 Prefix (folder path)\n",
    "\n",
    "S3 Suffix (example .json.gz)\n",
    "\n",
    "Region (ap-south-1 etc.)\n",
    "\n",
    "IAM Access key/Secret OR IAM Role assumption for Splunk\n",
    "\n",
    "Confirm SNS → SQS subscription is done\n",
    "\n",
    "Confirm CloudWatch log group name\n",
    "\n",
    "CloudWatch subscription filter → Lambda → S3 and S3 event → SNS → SQS are configured.\n",
    "\n",
    "\n",
    "1) Check if logs are coming (basic)\n",
    "index=aws_security earliest=-15m\n",
    "\n",
    "2) Check CloudWatch sourcetype only\n",
    "index=aws_security sourcetype=\"aws:cloudwatch:logs\" earliest=-15m\n",
    "\n",
    "3) Check latest event time (data freshness)\n",
    "index=aws_security sourcetype=\"aws:cloudwatch:logs\"\n",
    "| stats latest(_time) as last_event_time count\n",
    "| convert ctime(last_event_time)\n",
    "\n",
    "4) Check if there is a gap (missing logs)\n",
    "index=aws_security sourcetype=\"aws:cloudwatch:logs\" earliest=-2h\n",
    "| timechart span=5m count\n",
    "\n",
    "\n",
    "✅ If some 5-min buckets show 0, ingestion delay/issues.\n",
    "\n",
    "5) Check TA-AWS errors in Splunk (important)\n",
    "index=_internal sourcetype=splunkd (\"aws\" OR \"SQS\" OR \"S3\") (\"ERROR\" OR \"AccessDenied\" OR \"Signature\")\n",
    "\n",
    "6) Confirm SQS polling working\n",
    "index=_internal sourcetype=splunkd \"sqs\" (\"ReceiveMessage\" OR \"poll\")\n",
    "\n",
    "7) Confirm S3 download happening\n",
    "index=_internal sourcetype=splunkd \"s3\" (\"GetObject\" OR \"download\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
